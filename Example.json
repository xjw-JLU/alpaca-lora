{"train_data_step": [0, 1, 2, 3], "eval_loss": 128.5730743408203, "step": 1, "epoch": 0.04}
{"train_data_step": [4, 5, 6, 7], "eval_loss": 128.07638549804688, "step": 2, "epoch": 0.08}
{"train_data_step": [8, 9, 10, 11], "eval_loss": 127.26800537109375, "step": 3, "epoch": 0.12}
{"train_data_step": [12, 13, 14, 15], "eval_loss": 126.06893920898438, "step": 4, "epoch": 0.16}
{"train_data_step": [16, 17, 18, 19], "eval_loss": 124.39602661132812, "step": 5, "epoch": 0.2}
{"train_data_step": [20, 21, 22, 23], "eval_loss": 122.29830169677734, "step": 6, "epoch": 0.24}
{"train_data_step": [24, 25, 26, 27], "eval_loss": 119.91910552978516, "step": 7, "epoch": 0.28}
{"train_data_step": [28, 29, 30, 31], "eval_loss": 117.12626647949219, "step": 8, "epoch": 0.32}
{"train_data_step": [32, 33, 34, 35], "eval_loss": 113.52510070800781, "step": 9, "epoch": 0.36}
{"train_data_step": [36, 37, 38, 39], "eval_loss": 108.26695251464844, "step": 10, "epoch": 0.4}
{"train_data_step": [40, 41, 42, 43], "eval_loss": 102.472412109375, "step": 11, "epoch": 0.44}
{"train_data_step": [44, 45, 46, 47], "eval_loss": 96.79570007324219, "step": 12, "epoch": 0.48}
{"train_data_step": [48, 49, 50, 51], "eval_loss": 91.43543243408203, "step": 13, "epoch": 0.52}
{"train_data_step": [52, 53, 54, 55], "eval_loss": 84.28624725341797, "step": 14, "epoch": 0.56}
{"train_data_step": [56, 57, 58, 59], "eval_loss": 72.75458526611328, "step": 15, "epoch": 0.6}
{"train_data_step": [60, 61, 62, 63], "eval_loss": 54.58179473876953, "step": 16, "epoch": 0.64}
{"train_data_step": [64, 65, 66, 67], "eval_loss": 27.214187622070312, "step": 17, "epoch": 0.68}
{"train_data_step": [68, 69, 70, 71], "eval_loss": 4.720250129699707, "step": 18, "epoch": 0.72}
{"train_data_step": [72, 73, 74, 75], "eval_loss": 4.976314067840576, "step": 19, "epoch": 0.76}
{"train_data_step": [76, 77, 78, 79], "eval_loss": 5.287430763244629, "step": 20, "epoch": 0.8}
{"train_data_step": [80, 81, 82, 83], "eval_loss": 5.593132495880127, "step": 21, "epoch": 0.84}
{"train_data_step": [84, 85, 86, 87], "eval_loss": 5.864225387573242, "step": 22, "epoch": 0.88}
{"train_data_step": [88, 89, 90, 91], "eval_loss": 6.061077117919922, "step": 23, "epoch": 0.92}
{"train_data_step": [92, 93, 94, 95], "eval_loss": 6.148741722106934, "step": 24, "epoch": 0.96}
{"train_data_step": [96, 97, 98, 99], "eval_loss": 6.130794048309326, "step": 25, "epoch": 1.0}
{"train_data_step": [100, 101, 102, 103], "eval_loss": 6.089669227600098, "step": 26, "epoch": 1.04}
{"train_data_step": [104, 105, 106, 107], "eval_loss": 6.05356502532959, "step": 27, "epoch": 1.08}
{"train_data_step": [108, 109, 110, 111], "eval_loss": 6.021611213684082, "step": 28, "epoch": 1.12}
{"train_data_step": [112, 113, 114, 115], "eval_loss": 5.991236209869385, "step": 29, "epoch": 1.16}
{"train_data_step": [116, 117, 118, 119], "eval_loss": 5.9547505378723145, "step": 30, "epoch": 1.2}
{"train_data_step": [120, 121, 122, 123], "eval_loss": 5.9372453689575195, "step": 31, "epoch": 1.24}
{"train_data_step": [124, 125, 126, 127], "eval_loss": 5.961440086364746, "step": 32, "epoch": 1.28}
{"train_data_step": [128, 129, 130, 131], "eval_loss": 5.995154857635498, "step": 33, "epoch": 1.32}
{"train_data_step": [132, 133, 134, 135], "eval_loss": 6.033414840698242, "step": 34, "epoch": 1.3599999999999999}
{"train_data_step": [136, 137, 138, 139], "eval_loss": 6.075745582580566, "step": 35, "epoch": 1.4}
{"train_data_step": [140, 141, 142, 143], "eval_loss": 6.129331111907959, "step": 36, "epoch": 1.44}
{"train_data_step": [144, 145, 146, 147], "eval_loss": 6.170269966125488, "step": 37, "epoch": 1.48}
{"train_data_step": [148, 149, 150, 151], "eval_loss": 6.2183732986450195, "step": 38, "epoch": 1.52}
{"train_data_step": [152, 153, 154, 155], "eval_loss": 6.219592571258545, "step": 39, "epoch": 1.56}
{"train_data_step": [156, 157, 158, 159], "eval_loss": 6.2297468185424805, "step": 40, "epoch": 1.6}
{"train_data_step": [160, 161, 162, 163], "eval_loss": 6.1965508460998535, "step": 41, "epoch": 1.6400000000000001}
{"train_data_step": [164, 165, 166, 167], "eval_loss": 6.02869176864624, "step": 42, "epoch": 1.6800000000000002}
{"train_data_step": [168, 169, 170, 171], "eval_loss": 5.834832191467285, "step": 43, "epoch": 1.72}
{"train_data_step": [172, 173, 174, 175], "eval_loss": 5.6517815589904785, "step": 44, "epoch": 1.76}
{"train_data_step": [176, 177, 178, 179], "eval_loss": 5.515382289886475, "step": 45, "epoch": 1.8}
{"train_data_step": [180, 181, 182, 183], "eval_loss": 5.425038814544678, "step": 46, "epoch": 1.8399999999999999}
{"train_data_step": [184, 185, 186, 187], "eval_loss": 5.393387794494629, "step": 47, "epoch": 1.88}
{"train_data_step": [188, 189, 190, 191], "eval_loss": 5.390987396240234, "step": 48, "epoch": 1.92}
{"train_data_step": [192, 193, 194, 195], "eval_loss": 5.40113639831543, "step": 49, "epoch": 1.96}
{"train_data_step": [196, 197, 198, 199], "eval_loss": 5.427489757537842, "step": 50, "epoch": 2.0}
{"train_data_step": [200, 201, 202, 203], "eval_loss": 5.493206024169922, "step": 51, "epoch": 2.04}
{"train_data_step": [204, 205, 206, 207], "eval_loss": 5.544863224029541, "step": 52, "epoch": 2.08}
{"train_data_step": [208, 209, 210, 211], "eval_loss": 5.6237359046936035, "step": 53, "epoch": 2.12}
{"train_data_step": [212, 213, 214, 215], "eval_loss": 5.721624851226807, "step": 54, "epoch": 2.16}
{"train_data_step": [216, 217, 218, 219], "eval_loss": 5.7930521965026855, "step": 55, "epoch": 2.2}
{"train_data_step": [220, 221, 222, 223], "eval_loss": 5.859116554260254, "step": 56, "epoch": 2.24}
{"train_data_step": [224, 225, 226, 227], "eval_loss": 5.915205478668213, "step": 57, "epoch": 2.2800000000000002}
{"train_data_step": [228, 229, 230, 231], "eval_loss": 5.982780933380127, "step": 58, "epoch": 2.32}
{"train_data_step": [232, 233, 234, 235], "eval_loss": 6.1303181648254395, "step": 59, "epoch": 2.36}
{"train_data_step": [236, 237, 238, 239], "eval_loss": 6.2623982429504395, "step": 60, "epoch": 2.4}
{"train_data_step": [240, 241, 242, 243], "eval_loss": 6.409463882446289, "step": 61, "epoch": 2.44}
{"train_data_step": [244, 245, 246, 247], "eval_loss": 6.5192389488220215, "step": 62, "epoch": 2.48}
{"train_data_step": [248, 249, 250, 251], "eval_loss": 6.622070789337158, "step": 63, "epoch": 2.52}
{"train_data_step": [252, 253, 254, 255], "eval_loss": 6.7946248054504395, "step": 64, "epoch": 2.56}
{"train_data_step": [256, 257, 258, 259], "eval_loss": 6.96066951751709, "step": 65, "epoch": 2.6}
{"train_data_step": [260, 261, 262, 263], "eval_loss": 7.042134761810303, "step": 66, "epoch": 2.64}
{"train_data_step": [264, 265, 266, 267], "eval_loss": 7.106349945068359, "step": 67, "epoch": 2.68}
{"train_data_step": [268, 269, 270, 271], "eval_loss": 7.125324726104736, "step": 68, "epoch": 2.7199999999999998}
{"train_data_step": [272, 273, 274, 275], "eval_loss": 7.166034698486328, "step": 69, "epoch": 2.76}
{"train_data_step": [276, 277, 278, 279], "eval_loss": 7.249556541442871, "step": 70, "epoch": 2.8}
{"train_data_step": [280, 281, 282, 283], "eval_loss": 7.3759765625, "step": 71, "epoch": 2.84}
{"train_data_step": [284, 285, 286, 287], "eval_loss": 7.401158332824707, "step": 72, "epoch": 2.88}
{"train_data_step": [288, 289, 290, 291], "eval_loss": 7.423073768615723, "step": 73, "epoch": 2.92}
{"train_data_step": [292, 293, 294, 295], "eval_loss": 7.468623638153076, "step": 74, "epoch": 2.96}
{"train_data_step": [296, 297, 298, 299], "eval_loss": 7.538456439971924, "step": 75, "epoch": 3.0}
{"train_data_step": [300, 301, 302, 303], "eval_loss": 7.601943016052246, "step": 76, "epoch": 3.04}
{"train_data_step": [304, 305, 306, 307], "eval_loss": 7.712006568908691, "step": 77, "epoch": 3.08}
{"train_data_step": [308, 309, 310, 311], "eval_loss": 7.761107444763184, "step": 78, "epoch": 3.12}
{"train_data_step": [312, 313, 314, 315], "eval_loss": 7.840045928955078, "step": 79, "epoch": 3.16}
{"train_data_step": [316, 317, 318, 319], "eval_loss": 7.877198696136475, "step": 80, "epoch": 3.2}
{"train_data_step": [320, 321, 322, 323], "eval_loss": 7.9102020263671875, "step": 81, "epoch": 3.24}
{"train_data_step": [324, 325, 326, 327], "eval_loss": 7.957616329193115, "step": 82, "epoch": 3.2800000000000002}
{"train_data_step": [328, 329, 330, 331], "eval_loss": 8.222969055175781, "step": 83, "epoch": 3.32}
{"train_data_step": [332, 333, 334, 335], "eval_loss": 8.541478157043457, "step": 84, "epoch": 3.36}
{"train_data_step": [336, 337, 338, 339], "eval_loss": 8.573450088500977, "step": 85, "epoch": 3.4}
{"train_data_step": [340, 341, 342, 343], "eval_loss": 8.950973510742188, "step": 86, "epoch": 3.44}
{"train_data_step": [344, 345, 346, 347], "eval_loss": 9.905377388000488, "step": 87, "epoch": 3.48}
{"train_data_step": [348, 349, 350, 351], "eval_loss": 11.065506935119629, "step": 88, "epoch": 3.52}
{"train_data_step": [352, 353, 354, 355], "eval_loss": 12.032278060913086, "step": 89, "epoch": 3.56}
{"train_data_step": [356, 357, 358, 359], "eval_loss": 11.4222993850708, "step": 90, "epoch": 3.6}
{"train_data_step": [360, 361, 362, 363], "eval_loss": 10.834096908569336, "step": 91, "epoch": 3.64}
{"train_data_step": [364, 365, 366, 367], "eval_loss": 10.311366081237793, "step": 92, "epoch": 3.68}
{"train_data_step": [368, 369, 370, 371], "eval_loss": 9.906904220581055, "step": 93, "epoch": 3.7199999999999998}
{"train_data_step": [372, 373, 374, 375], "eval_loss": 9.674606323242188, "step": 94, "epoch": 3.76}
{"train_data_step": [376, 377, 378, 379], "eval_loss": 9.42825698852539, "step": 95, "epoch": 3.8}
{"train_data_step": [380, 381, 382, 383], "eval_loss": 9.425639152526855, "step": 96, "epoch": 3.84}
{"train_data_step": [384, 385, 386, 387], "eval_loss": 9.401464462280273, "step": 97, "epoch": 3.88}
{"train_data_step": [388, 389, 390, 391], "eval_loss": 9.366436958312988, "step": 98, "epoch": 3.92}
{"train_data_step": [392, 393, 394, 395], "eval_loss": 9.149174690246582, "step": 99, "epoch": 3.96}
{"train_data_step": [396, 397, 398, 399], "eval_loss": 9.053070068359375, "step": 100, "epoch": 4.0}
